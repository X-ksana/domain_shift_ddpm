putecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
[W socket.cpp:601] [c10d] The IPv6 network addresses of (172.31.112.60computecomputecomputecomputecomputecomputeall, 12345) cannot be retrieved (gai error: -2 - Name or service not known).
srun: Job step aborted: Waiting up to 92 seconds for job step to finish.
slurmstepd: error: *** JOB 668184 ON dgk210 CANCELLED AT 2024-07-07T18:20:24 ***
slurmstepd: error: *** STEP 668184.1 ON dgk210 CANCELLED AT 2024-07-07T18:20:24 ***
(mo_ninja) [xxw55-mtc03@dgk327 DDA]$ ls
ckpt                        slurm-659784.out  slurm-666009.out
dataset                     slurm-659798.out  slurm-666010.out
dda_loop_sample1.sh         slurm-659877.out  slurm-666012.out
dda_loop_sample.sh          slurm-659886.out  slurm-666015.out
dda_test_noloop.sh          slurm-662526.out  slurm-666248.out
dda_test_one.sh             slurm-662541.out  slurm-667631.out
dda_test_scaleloop.sh       slurm-662985.out  slurm-667634.out
dda_test.sh                 slurm-662986.out  slurm-667649.out
download_ckpt.sh            slurm-662988.out  slurm-667655.out
image_adapt                 slurm-663616.out  slurm-667656.out
image_adapt_original.sh     slurm-663655.out  slurm-667680.out
image_adapt.sh              slurm-665987.out  slurm-668111.out
model_adapt                 slurm-665988.out  slurm-668179.out
multiprocessing-errors.out  slurm-665996.out  slurm-668184.out
OUTPUT_DIR                  slurm-666001.out  test.sh
README.md                   slurm-666007.out
(mo_ninja) [xxw55-mtc03@dgk327 DDA]$ mv slurm-668184.out slurm-668184-ipnetworkerror.out
(mo_ninja) [xxw55-mtc03@dgk327 DDA]$ ls
ckpt                        slurm-659784.out  slurm-666009.out
dataset                     slurm-659798.out  slurm-666010.out
dda_loop_sample1.sh         slurm-659877.out  slurm-666012.out
dda_loop_sample.sh          slurm-659886.out  slurm-666015.out
dda_test_noloop.sh          slurm-662526.out  slurm-666248.out
dda_test_one.sh             slurm-662541.out  slurm-667631.out
dda_test_scaleloop.sh       slurm-662985.out  slurm-667634.out
dda_test.sh                 slurm-662986.out  slurm-667649.out
download_ckpt.sh            slurm-662988.out  slurm-667655.out
image_adapt                 slurm-663616.out  slurm-667656.out
image_adapt_original.sh     slurm-663655.out  slurm-667680.out
image_adapt.sh              slurm-665987.out  slurm-668111.out
model_adapt                 slurm-665988.out  slurm-668179.out
multiprocessing-errors.out  slurm-665996.out  slurm-668184-ipnetworkerror.out
OUTPUT_DIR                  slurm-666001.out  test.sh
README.md                   slurm-666007.out
(mo_ninja) [xxw55-mtc03@dgk327 DDA]$ cat dda_test_one.sh
#!/bin/bash
# Xin Ci 21 Jun 2024 - DDA

# set the number of nodes
#SBATCH --nodes=1

# set max wallclock time
#SBATCH --time=0-00:30:00

# set name of job
#SBATCH --job-name=red_velvet_cosmic

# set number of GPUs
#SBATCH --gres=gpu:1

# mail alert at start, end and abortion of execution
#SBATCH --mail-type=ALL

# send mail to this address
#SBATCH --mail-user=scxcw@leeds.ac.uk

# run the application
date
export PYTHONPATH=$PYTHONPATH:$(pwd)

# Define the values for D and N
D_values=(2 4 8)
N_values=(25 50)

# Define the base command and other flags
MODEL_FLAGS="--attention_resolutions 16 --class_cond False --diffusion_steps 1000 --image_size 128 --learn_sigma True --noise_schedule linear --num_channels 128 --num_head_channels 64 --num_res_blocks 1 --resblock_updown True --use_fp16 False --use_scale_shift_norm True"
COMMON_ARGS="--batch_size 1 --num_samples 1 --timestep_respacing 100 --model_path /jmain02/home/J2AD014/mtc03/xxw55-mtc03/ilvr_adm/logging_21Jun_cardiac_1000steps_ilvr/ema_0.9999_120000.pt --base_samples /jmain02/home/J2AD014/mtc03/xxw55-mtc03/ilvr_adm/ref_imgs --scale 6"

# Loop over each combination of D and N
for D in "${D_values[@]}"; do
    for N in "${N_values[@]}"; do
        # Define a unique save directory
        SAVE_DIR="dataset/generated/D${D}_N${N}"

        # Construct the specific command for the current values of D and N
        COMMAND="python image_adapt/scripts/image_sample.py $MODEL_FLAGS $COMMON_ARGS --D $D --N $N --save_dir $SAVE_DIR"

        # Print the command being run
        echo "Running: $COMMAND"

        # Run the command
        $COMMAND
    done
done


date
(mo_ninja) [xxw55-mtc03@dgk327 DDA]$ ls
ckpt                        slurm-659784.out  slurm-666009.out
dataset                     slurm-659798.out  slurm-666010.out
dda_loop_sample1.sh         slurm-659877.out  slurm-666012.out
dda_loop_sample.sh          slurm-659886.out  slurm-666015.out
dda_test_noloop.sh          slurm-662526.out  slurm-666248.out
dda_test_one.sh             slurm-662541.out  slurm-667631.out
dda_test_scaleloop.sh       slurm-662985.out  slurm-667634.out
dda_test.sh                 slurm-662986.out  slurm-667649.out
download_ckpt.sh            slurm-662988.out  slurm-667655.out
image_adapt                 slurm-663616.out  slurm-667656.out
image_adapt_original.sh     slurm-663655.out  slurm-667680.out
image_adapt.sh              slurm-665987.out  slurm-668111.out
model_adapt                 slurm-665988.out  slurm-668179.out
multiprocessing-errors.out  slurm-665996.out  slurm-668184-ipnetworkerror.out
OUTPUT_DIR                  slurm-666001.out  test.sh
README.md                   slurm-666007.out
(mo_ninja) [xxw55-mtc03@dgk327 DDA]$ cd image_adapt
(mo_ninja) [xxw55-mtc03@dgk327 image_adapt]$ ls
guided_diffusion   __pycache__      scripts
interp_methods.py  resize_right.py  setup.py
(mo_ninja) [xxw55-mtc03@dgk327 image_adapt]$ cd scripts/
(mo_ninja) [xxw55-mtc03@dgk327 scripts]$ ls
ilvr_sample.py               image_sample_origin.py  image_sample_toedit.py
image_sample_failednifti.py  image_sample.py         image_sample_useforloop.py
(mo_ninja) [xxw55-mtc03@dgk327 scripts]$ cat image_sample_useforloop.py
import argparse
import os

import blobfile as bf
import numpy as np
import torch as th
import torch.distributed as dist

from image_adapt.guided_diffusion import dist_util, logger
from image_adapt.guided_diffusion.script_util import (
    model_and_diffusion_defaults,
    create_model_and_diffusion,
    args_to_dict,
    add_dict_to_argparser,
)
from image_adapt.guided_diffusion.image_datasets import load_data
from torchvision import utils
import math
from torch.nn.parallel.distributed import DistributedDataParallel as DDP


# added
# to remove corruption and severity
def load_reference(data_dir, batch_size, image_size, class_cond=False):
    data = load_data(
        data_dir=data_dir,
        batch_size=batch_size,
        image_size=image_size,
        class_cond=class_cond,
        deterministic=True,
        random_flip=False,

    )
    for large_batch, model_kwargs in data:
        model_kwargs["ref_img"] = large_batch
        yield model_kwargs


def main():
    args = create_argparser().parse_args()

    # th.manual_seed(0)

    dist_util.setup_dist()
    logger.configure(dir=args.save_dir)

    logger.log("creating model...")
    model, diffusion = create_model_and_diffusion(
        **args_to_dict(args, model_and_diffusion_defaults().keys())
    )
    model.load_state_dict(
        dist_util.load_state_dict(args.model_path, map_location="cpu")
    )
    model.to(dist_util.dev())
    if args.use_fp16:
        model.convert_to_fp16()

    model = DDP(
        model,
        device_ids=[dist_util.dev()],
        output_device=dist_util.dev(),
        broadcast_buffers=False,
        bucket_cap_mb=128,
        find_unused_parameters=False,
    )
    model.eval()

    logger.log("creating resizers...")
    assert math.log(args.D, 2).is_integer()

    logger.log("loading data...")
    data = load_reference(
        args.base_samples,
        args.batch_size,
        image_size=args.image_size,
        class_cond=args.class_cond,
    )

    assert args.num_samples >= args.batch_size * dist_util.get_world_size(), "The number of the generated samples will be larger than the specified number."


    logger.log("creating samples...")
    count = 0
    while count * args.batch_size * dist_util.get_world_size() < args.num_samples:
        model_kwargs = next(data)
        model_kwargs = {k: v.to(dist_util.dev()) for k, v in model_kwargs.items()}
        sample = diffusion.p_sample_loop(
            model,
            (args.batch_size, 1, args.image_size, args.image_size),
            clip_denoised=args.clip_denoised,
            model_kwargs=model_kwargs,
            noise=model_kwargs["ref_img"],
            N=args.N,
            D=args.D,
            scale=args.scale
        )

        for i in range(args.batch_size):
            out_path = os.path.join(logger.get_dir(),f"{str(count * args.batch_size + i).zfill(5)}.png")


            """
            path = os.path.join(logger.get_dir(), args.corruption, str(args.severity), filename[i].split('/')[0])
            os.makedirs(path, exist_ok=True)
            out_path = os.path.join(path, filename[i].split('/')[1])

            """
            utils.save_image(
                sample[i].unsqueeze(0),
                out_path,
                nrow=1,
                normalize=True,
                range=(-1, 1),
            )

        count += 1
        logger.log(f"created {count * args.batch_size * dist_util.get_world_size()} samples")

    dist.barrier()
    logger.log("sampling complete")


def create_argparser():
    defaults = dict(
        clip_denoised=True,
        num_samples=10000,
        batch_size=4,
        D=32, # scaling factor
        N=50,
        scale=1,
        use_ddim=False,
        base_samples="",
        model_path="",
        save_dir="",
        save_latents=False,
        corruption="shot_noise",
        severity=5,
    )
    defaults.update(model_and_diffusion_defaults())
    parser = argparse.ArgumentParser()
    add_dict_to_argparser(parser, defaults)
    return parser


if __name__ == "__main__":
    main()
(mo_ninja) [xxw55-mtc03@dgk327 scripts]$ ls
ilvr_sample.py               image_sample_origin.py  image_sample_toedit.py
image_sample_failednifti.py  image_sample.py         image_sample_useforloop.py
(mo_ninja) [xxw55-mtc03@dgk327 scripts]$ cat image_sample.py
import argparse
import os

import blobfile as bf
import numpy as np
import torch as th
import torch.distributed as dist

from image_adapt.guided_diffusion import dist_util, logger
from image_adapt.guided_diffusion.script_util import (
    model_and_diffusion_defaults,
    create_model_and_diffusion,
    args_to_dict,
    add_dict_to_argparser,
)
from image_adapt.guided_diffusion.image_datasets import load_data
from torchvision import utils
import math
from torch.nn.parallel.distributed import DistributedDataParallel as DDP

import nibabel as nib



# added
# to remove corruption and severity
def load_reference(data_dir, batch_size, image_size, class_cond=False):
    data = load_data(
        data_dir=data_dir,
        batch_size=batch_size,
        image_size=image_size,
        class_cond=class_cond,
        deterministic=True,
        random_flip=False,

    )
    for large_batch, model_kwargs in data:
        for ref_img in large_batch:
            model_kwargs["ref_img"] = ref_img.unsqueeze(0)
            yield model_kwargs


def main():
    args = create_argparser().parse_args()
  #  parser.add_argument('--output_file', type=str, required=True, help="Output filename for the generated image")
  #  parser = argparse.ArgumentParser(description="Generate images")
  #  args = parser.parse_args()
    # th.manual_seed(0)

    dist_util.setup_dist()
    logger.configure(dir=args.save_dir)

    logger.log("creating model...")
    model, diffusion = create_model_and_diffusion(
        **args_to_dict(args, model_and_diffusion_defaults().keys())
    )
    model.load_state_dict(
        dist_util.load_state_dict(args.model_path, map_location="cpu")
    )
    model.to(dist_util.dev())
    if args.use_fp16:
        model.convert_to_fp16()

    model = DDP(
        model,
        device_ids=[dist_util.dev()],
        output_device=dist_util.dev(),
        broadcast_buffers=False,
        bucket_cap_mb=128,
        find_unused_parameters=False,
    )
    model.eval()

    logger.log("creating resizers...")
    assert math.log(args.D, 2).is_integer()

    logger.log("loading data...")
    data = load_reference(
        args.base_samples,
        args.batch_size,
        image_size=args.image_size,
        class_cond=args.class_cond,
    )

    assert args.num_samples >= args.batch_size * dist_util.get_world_size(), "The number of the generated samples will be larger than the specified number."


    logger.log("creating samples...")
    count = 0



    while count * args.batch_size * dist_util.get_world_size() < args.num_samples:
        model_kwargs = next(data)
        model_kwargs = {k: v.to(dist_util.dev()) for k, v in model_kwargs.items()}
        sample = diffusion.p_sample_loop(
            model,
            (args.batch_size, 1, args.image_size, args.image_size),
            clip_denoised=args.clip_denoised,
            model_kwargs=model_kwargs,
            noise=model_kwargs["ref_img"],
            N=args.N,
            D=args.D,
            scale=args.scale
        )

        for i in range(args.batch_size):
            ref_img_name = model_kwargs["ref_img_names"][i]
        out_path = os.path.join(logger.get_dir(), f"{ref_img_name}.png")
        out_path_nifti = os.path.join(logger.get_dir(), f"{ref_img_name}.nii.gz")

        utils.save_image(
            sample[i].unsqueeze(0),
            out_path,
            nrow=1,
            normalize=True,
            range=(-1, 1),
        )

        # save as nifti
        sample_data = sample[i].unsqueeze(0).cpu().detach().numpy()
        print("Data range before normalization:", sample_data.min(), sample_data.max())
        sample_data = (sample_data - sample_data.min()) / (sample_data.max() - sample_data.min())
        sample_data = (sample_data * 255).astype(np.uint8)
        print("Data range after normalization:", sample_data.min(), sample_data.max())

        header = nib.Nifti1Header()
        header.set_data_dtype(np.dtype(np.float32))  # Adjust dtype as per your image data type
        nifti_img = nib.Nifti1Image(sample_data, affine=np.eye(4), header=header)
        nib.save(nifti_img, out_path_nifti)

    count += 1
    logger.log(f"created {count * args.batch_size * dist_util.get_world_size()} samples")

dist.barrier()
logger.log("sampling complete")


def create_argparser():
    defaults = dict(
        clip_denoised=True,
        num_samples=10000,
        batch_size=4,
        D=32, # scaling factor
        N=50,
        scale=1,
        use_ddim=False,
        base_samples="",
        model_path="",
        save_dir="",
        save_latents=False,
        corruption="shot_noise",
        severity=5,
    )
    defaults.update(model_and_diffusion_defaults())
    parser = argparse.ArgumentParser()
    parser.add_argument('--output_file', type=str, required=True, help="Output filename for the generated image")
    add_dict_to_argparser(parser, defaults)
    return parser


if __name__ == "__main__":
    main()
(mo_ninja) [xxw55-mtc03@dgk327 scripts]$ cat image_sample_useforloop.py
import argparse
import os

import blobfile as bf
import numpy as np
import torch as th
import torch.distributed as dist

from image_adapt.guided_diffusion import dist_util, logger
from image_adapt.guided_diffusion.script_util import (
    model_and_diffusion_defaults,
    create_model_and_diffusion,
    args_to_dict,
    add_dict_to_argparser,
)
from image_adapt.guided_diffusion.image_datasets import load_data
from torchvision import utils
import math
from torch.nn.parallel.distributed import DistributedDataParallel as DDP


# added
# to remove corruption and severity
def load_reference(data_dir, batch_size, image_size, class_cond=False):
    data = load_data(
        data_dir=data_dir,
        batch_size=batch_size,
        image_size=image_size,
        class_cond=class_cond,
        deterministic=True,
        random_flip=False,

    )
    for large_batch, model_kwargs in data:
        model_kwargs["ref_img"] = large_batch
        yield model_kwargs


def main():
    args = create_argparser().parse_args()

    # th.manual_seed(0)

    dist_util.setup_dist()
    logger.configure(dir=args.save_dir)

    logger.log("creating model...")
    model, diffusion = create_model_and_diffusion(
        **args_to_dict(args, model_and_diffusion_defaults().keys())
    )
    model.load_state_dict(
        dist_util.load_state_dict(args.model_path, map_location="cpu")
    )
    model.to(dist_util.dev())
    if args.use_fp16:
        model.convert_to_fp16()

    model = DDP(
        model,
        device_ids=[dist_util.dev()],
        output_device=dist_util.dev(),
        broadcast_buffers=False,
        bucket_cap_mb=128,
        find_unused_parameters=False,
    )
    model.eval()

    logger.log("creating resizers...")
    assert math.log(args.D, 2).is_integer()

    logger.log("loading data...")
    data = load_reference(
        args.base_samples,
        args.batch_size,
        image_size=args.image_size,
        class_cond=args.class_cond,
    )

    assert args.num_samples >= args.batch_size * dist_util.get_world_size(), "The number of the generated samples will be larger than the specified number."


    logger.log("creating samples...")
    count = 0
    while count * args.batch_size * dist_util.get_world_size() < args.num_samples:
        model_kwargs = next(data)
        model_kwargs = {k: v.to(dist_util.dev()) for k, v in model_kwargs.items()}
        sample = diffusion.p_sample_loop(
            model,
            (args.batch_size, 1, args.image_size, args.image_size),
            clip_denoised=args.clip_denoised,
            model_kwargs=model_kwargs,
            noise=model_kwargs["ref_img"],
            N=args.N,
            D=args.D,
            scale=args.scale
        )

        for i in range(args.batch_size):
            out_path = os.path.join(logger.get_dir(),f"{str(count * args.batch_size + i).zfill(5)}.png")


            """
            path = os.path.join(logger.get_dir(), args.corruption, str(args.severity), filename[i].split('/')[0])
            os.makedirs(path, exist_ok=True)
            out_path = os.path.join(path, filename[i].split('/')[1])

            """
            utils.save_image(
                sample[i].unsqueeze(0),
                out_path,
                nrow=1,
                normalize=True,
                range=(-1, 1),
            )

        count += 1
        logger.log(f"created {count * args.batch_size * dist_util.get_world_size()} samples")

    dist.barrier()
    logger.log("sampling complete")


def create_argparser():
    defaults = dict(
        clip_denoised=True,
        num_samples=10000,
        batch_size=4,
        D=32, # scaling factor
        N=50,
        scale=1,
        use_ddim=False,
        base_samples="",
        model_path="",
        save_dir="",
        save_latents=False,
        corruption="shot_noise",
        severity=5,
    )
    defaults.update(model_and_diffusion_defaults())
    parser = argparse.ArgumentParser()
    add_dict_to_argparser(parser, defaults)
    return parser


if __name__ == "__main__":
    main()
(mo_ninja) [xxw55-mtc03@dgk327 scripts]$ cat image_sample.py
import argparse
import os

import blobfile as bf
import numpy as np
import torch as th
import torch.distributed as dist

from image_adapt.guided_diffusion import dist_util, logger
from image_adapt.guided_diffusion.script_util import (
    model_and_diffusion_defaults,
    create_model_and_diffusion,
    args_to_dict,
    add_dict_to_argparser,
)
from image_adapt.guided_diffusion.image_datasets import load_data
from torchvision import utils
import math
from torch.nn.parallel.distributed import DistributedDataParallel as DDP

import nibabel as nib



# added
# to remove corruption and severity
def load_reference(data_dir, batch_size, image_size, class_cond=False):
    data = load_data(
        data_dir=data_dir,
        batch_size=batch_size,
        image_size=image_size,
        class_cond=class_cond,
        deterministic=True,
        random_flip=False,

    )
    for large_batch, model_kwargs in data:
        for ref_img in large_batch:
            model_kwargs["ref_img"] = ref_img.unsqueeze(0)
            yield model_kwargs


def main():
    args = create_argparser().parse_args()
  #  parser.add_argument('--output_file', type=str, required=True, help="Output filename for the generated image")
  #  parser = argparse.ArgumentParser(description="Generate images")
  #  args = parser.parse_args()
    # th.manual_seed(0)

    dist_util.setup_dist()
    logger.configure(dir=args.save_dir)

    logger.log("creating model...")
    model, diffusion = create_model_and_diffusion(
        **args_to_dict(args, model_and_diffusion_defaults().keys())
    )
    model.load_state_dict(
        dist_util.load_state_dict(args.model_path, map_location="cpu")
    )
    model.to(dist_util.dev())
    if args.use_fp16:
        model.convert_to_fp16()

    model = DDP(
        model,
        device_ids=[dist_util.dev()],
        output_device=dist_util.dev(),
        broadcast_buffers=False,
        bucket_cap_mb=128,
        find_unused_parameters=False,
    )
    model.eval()

    logger.log("creating resizers...")
    assert math.log(args.D, 2).is_integer()

    logger.log("loading data...")
    data = load_reference(
        args.base_samples,
        args.batch_size,
        image_size=args.image_size,
        class_cond=args.class_cond,
    )

    assert args.num_samples >= args.batch_size * dist_util.get_world_size(), "The number of the generated samples will be larger than the specified number."


    logger.log("creating samples...")
    count = 0



    while count * args.batch_size * dist_util.get_world_size() < args.num_samples:
        model_kwargs = next(data)
        model_kwargs = {k: v.to(dist_util.dev()) for k, v in model_kwargs.items()}
        sample = diffusion.p_sample_loop(
            model,
            (args.batch_size, 1, args.image_size, args.image_size),
            clip_denoised=args.clip_denoised,
            model_kwargs=model_kwargs,
            noise=model_kwargs["ref_img"],
            N=args.N,
            D=args.D,
            scale=args.scale
        )

        for i in range(args.batch_size):
            ref_img_name = model_kwargs["ref_img_names"][i]
        out_path = os.path.join(logger.get_dir(), f"{ref_img_name}.png")
        out_path_nifti = os.path.join(logger.get_dir(), f"{ref_img_name}.nii.gz")

        utils.save_image(
            sample[i].unsqueeze(0),
            out_path,
            nrow=1,
            normalize=True,
            range=(-1, 1),
        )

        # save as nifti
        sample_data = sample[i].unsqueeze(0).cpu().detach().numpy()
        print("Data range before normalization:", sample_data.min(), sample_data.max())
        sample_data = (sample_data - sample_data.min()) / (sample_data.max() - sample_data.min())
        sample_data = (sample_data * 255).astype(np.uint8)
        print("Data range after normalization:", sample_data.min(), sample_data.max())

        header = nib.Nifti1Header()
        header.set_data_dtype(np.dtype(np.float32))  # Adjust dtype as per your image data type
        nifti_img = nib.Nifti1Image(sample_data, affine=np.eye(4), header=header)
        nib.save(nifti_img, out_path_nifti)

    count += 1
    logger.log(f"created {count * args.batch_size * dist_util.get_world_size()} samples")

dist.barrier()
logger.log("sampling complete")


def create_argparser():
    defaults = dict(
        clip_denoised=True,
        num_samples=10000,
        batch_size=4,
        D=32, # scaling factor
        N=50,
        scale=1,
        use_ddim=False,
        base_samples="",
        model_path="",
        save_dir="",
        save_latents=False,
        corruption="shot_noise",
        severity=5,
    )
    defaults.update(model_and_diffusion_defaults())
    parser = argparse.ArgumentParser()
    parser.add_argument('--output_file', type=str, required=True, help="Output filename for the generated image")
    add_dict_to_argparser(parser, defaults)
    return parser


if __name__ == "__main__":
    main()
(mo_ninja) [xxw55-mtc03@dgk327 scripts]$ cat image_sample.py
import argparse
import os

import blobfile as bf
import numpy as np
import torch as th
import torch.distributed as dist

from image_adapt.guided_diffusion import dist_util, logger
from image_adapt.guided_diffusion.script_util import (
    model_and_diffusion_defaults,
    create_model_and_diffusion,
    args_to_dict,
    add_dict_to_argparser,
)
from image_adapt.guided_diffusion.image_datasets import load_data
from torchvision import utils
import math
from torch.nn.parallel.distributed import DistributedDataParallel as DDP

import nibabel as nib



# added
# to remove corruption and severity
def load_reference(data_dir, batch_size, image_size, class_cond=False):
    data = load_data(
        data_dir=data_dir,
        batch_size=batch_size,
        image_size=image_size,
        class_cond=class_cond,
        deterministic=True,
        random_flip=False,

    )
    for large_batch, model_kwargs in data:
        for ref_img in large_batch:
            model_kwargs["ref_img"] = ref_img.unsqueeze(0)
            yield model_kwargs


def main():
    args = create_argparser().parse_args()
  #  parser.add_argument('--output_file', type=str, required=True, help="Output filename for the generated image")
  #  parser = argparse.ArgumentParser(description="Generate images")
  #  args = parser.parse_args()
    # th.manual_seed(0)

    dist_util.setup_dist()
    logger.configure(dir=args.save_dir)

    logger.log("creating model...")
    model, diffusion = create_model_and_diffusion(
        **args_to_dict(args, model_and_diffusion_defaults().keys())
    )
    model.load_state_dict(
        dist_util.load_state_dict(args.model_path, map_location="cpu")
    )
    model.to(dist_util.dev())
    if args.use_fp16:
        model.convert_to_fp16()

    model = DDP(
        model,
        device_ids=[dist_util.dev()],
        output_device=dist_util.dev(),
        broadcast_buffers=False,
        bucket_cap_mb=128,
        find_unused_parameters=False,
    )
    model.eval()

    logger.log("creating resizers...")
    assert math.log(args.D, 2).is_integer()

    logger.log("loading data...")
    data = load_reference(
        args.base_samples,
        args.batch_size,
        image_size=args.image_size,
        class_cond=args.class_cond,
    )

    assert args.num_samples >= args.batch_size * dist_util.get_world_size(), "The number of the generated samples will be larger than the specified number."


    logger.log("creating samples...")
    count = 0



    while count * args.batch_size * dist_util.get_world_size() < args.num_samples:
        model_kwargs = next(data)
        model_kwargs = {k: v.to(dist_util.dev()) for k, v in model_kwargs.items()}
        sample = diffusion.p_sample_loop(
            model,
            (args.batch_size, 1, args.image_size, args.image_size),
            clip_denoised=args.clip_denoised,
            model_kwargs=model_kwargs,
            noise=model_kwargs["ref_img"],
            N=args.N,
            D=args.D,
            scale=args.scale
        )

        for i in range(args.batch_size):
            ref_img_name = model_kwargs["ref_img_names"][i]
        out_path = os.path.join(logger.get_dir(), f"{ref_img_name}.png")
        out_path_nifti = os.path.join(logger.get_dir(), f"{ref_img_name}.nii.gz")

        utils.save_image(
            sample[i].unsqueeze(0),
            out_path,
            nrow=1,
            normalize=True,
            range=(-1, 1),
        )

        # save as nifti
        sample_data = sample[i].unsqueeze(0).cpu().detach().numpy()
        print("Data range before normalization:", sample_data.min(), sample_data.max())
        sample_data = (sample_data - sample_data.min()) / (sample_data.max() - sample_data.min())
        sample_data = (sample_data * 255).astype(np.uint8)
        print("Data range after normalization:", sample_data.min(), sample_data.max())

        header = nib.Nifti1Header()
        header.set_data_dtype(np.dtype(np.float32))  # Adjust dtype as per your image data type
        nifti_img = nib.Nifti1Image(sample_data, affine=np.eye(4), header=header)
        nib.save(nifti_img, out_path_nifti)

    count += 1
    logger.log(f"created {count * args.batch_size * dist_util.get_world_size()} samples")

dist.barrier()
logger.log("sampling complete")


def create_argparser():
    defaults = dict(
        clip_denoised=True,
        num_samples=10000,
        batch_size=4,
        D=32, # scaling factor
        N=50,
        scale=1,
        use_ddim=False,
        base_samples="",
        model_path="",
        save_dir="",
        save_latents=False,
        corruption="shot_noise",
        severity=5,
    )
    defaults.update(model_and_diffusion_defaults())
    parser = argparse.ArgumentParser()
    parser.add_argument('--output_file', type=str, required=True, help="Output filename for the generated image")
    add_dict_to_argparser(parser, defaults)
    return parser


if __name__ == "__main__":
    main()
(mo_ninja) [xxw55-mtc03@dgk327 scripts]$
